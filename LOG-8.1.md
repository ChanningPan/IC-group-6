# 8.1 Lab 总结

## 项目预期

分为三种结果预期,结果记录为增量

### 最差成果预期
---
`一个简单的 用于展示的Demo`

* 简化运动控制方法,固定的目标1和目标2的位置

`Step 1 物件获取阶段`

* 由人工控制的服务开始
* 通过语音确定要识别的目标
* 识别不同的物体和其`二维`位置(2个)
* 可以控制机械臂朝物体方向运动(2维平面),不抓取
* 手动控制进入Step 2

`Step 2 物体递送阶段`

* 提前设定好的手部大致位置
* 机械臂通过设定好的控制方法到达目标位置
* 复位,回归最初位置,方便下次展示

### 中等成果预期
---
`基本实现社会主义自动化`

目标信息:目标1固定位置,目标2在二维平面内移动

`Step 1`

* 语音控制的服务开始
* 自动进入Step 2

`Step 2`
* 目标2在平面上移动
* 目标检测:皮肤在YCBCR颜色系中有更好表现,可使用该方法;同时,可使用记号法进行目标的识别
* 可根据手的位置(`目标检测`)进行追踪(`坐标->控制转换`)


### 最好成果预期
`深度社会主义自动化`

识别出深度信息

目标状况:目标1不动,目标2在三维空间中运动

`Step 1`

* 可以判断出目标1的深度信息
* 可以实际抓起物体

`Step 2`

* 自动判断手和机械臂的距离
* 机械臂可以跟着手的位置移动(完全的控制信息转换方法)

## 分工信息

### 目标检测

描述:识别目标1(医疗器具)和目标2(手掌)

高级目标描述:深度信息的采集,eg.aruco marker

`潘晨城` `蒋忍`

### 机械控制

描述:完成从pc到arduino的控制,提供分别控制6-axis的python方法, 标准化:完成从pwm波到实际角度的关系转换

`张庭源`

### 标定

描述:由物体的坐标信息到6-axis具体数值(角度)的转换,一套数学方法(或可找开源信息),最后给出python的`可调用方法`

`刘琼` `万之颖` (`潘晨城`)

### 语音

描述:识别语音信息,输出文本消息,给出一套可以调用的python软件系统(音频捕捉\\处理\\识别\\给出识别目标)

`张博`

## General

* 空间到坐标的转换算法
* 摄像头的摆放方法 物体的拜访位置